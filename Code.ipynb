{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification: CG vs. Camera in Google Colab**\n",
        "\n",
        "##This notebook implements the image classification task from the paper \"Forensic Techniques for Classifying Scanner, Computer Generated and Digital Camera Images\". The code uses all three RGB channels (45 features) to classify images as Computer Generated (CG) or Camera-captured, trains an SVM model, and saves the model, feature vectors, and confusion matrix."
      ],
      "metadata": {
        "id": "iMzFAIfo-ETX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QheMhPYZvw13"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python-headless scikit-image scikit-learn matplotlib Pillow seaborn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyWavelets\n",
        "!pip install pdf2image\n",
        "!apt-get update\n",
        "!apt-get install -y poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvM-m7H400rJ",
        "outputId": "e0750708-f0de-4ba5-fe49-d0631d3f95b7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (2.0.2)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.2.1)\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8 [186 kB]\n",
            "Fetched 186 kB in 0s (892 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Necessary libraries"
      ],
      "metadata": {
        "id": "EN8WQ_v6-21G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from pdf2image import convert_from_path\n",
        "from skimage.restoration import denoise_wavelet\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats\n",
        "import pandas as pd\n",
        "import joblib"
      ],
      "metadata": {
        "id": "2WnTuX516q7l"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating output directories"
      ],
      "metadata": {
        "id": "2wNDwaiwDPLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_base = \"/content/drive/MyDrive/DIP_Output\"\n",
        "cropped_dir = os.path.join(output_base, \"cropped_images\")\n",
        "results_dir = os.path.join(output_base, \"results\")\n",
        "os.makedirs(cropped_dir, exist_ok=True)\n",
        "os.makedirs(results_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "qpw4twqU6v0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function to Resize/crop image"
      ],
      "metadata": {
        "id": "GKMuKDSXDTjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def center_crop_image(filepath, output_path=None):\n",
        "    img = Image.open(filepath).convert(\"RGB\")\n",
        "    width, height = img.size\n",
        "    target_width, target_height = 1024, 768\n",
        "    if width < target_width or height < target_height:\n",
        "        img = img.resize((max(width, target_width), max(height, target_height)))\n",
        "        width, height = img.size\n",
        "    left = (width - target_width) // 2\n",
        "    top = (height - target_height) // 2\n",
        "    right = left + target_width\n",
        "    bottom = top + target_height\n",
        "    img_cropped = img.crop((left, top, right, bottom))\n",
        "    if output_path:\n",
        "        img_cropped.save(output_path)\n",
        "    return np.array(img_cropped)"
      ],
      "metadata": {
        "id": "bUBsxA-_7XB6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function to extract all 15 features in all three channels"
      ],
      "metadata": {
        "id": "p737ag_GDsUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(img):\n",
        "    # Ensure image is RGB\n",
        "    if len(img.shape) != 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    # Extract features from all three channels (R, G, B)\n",
        "    all_features = []\n",
        "    for channel in range(3):  # 0: Red, 1: Green, 2: Blue\n",
        "        img_channel = img[:, :, channel]\n",
        "\n",
        "        # Wavelet denoising and noise extraction\n",
        "        denoised = denoise_wavelet(img_channel, channel_axis=None, rescale_sigma=True)\n",
        "        noise = img_channel.astype(np.float32) - denoised.astype(np.float32)\n",
        "        M, N = noise.shape\n",
        "\n",
        "        # Row and column averages\n",
        "        r_avg = np.mean(noise, axis=0)  # 1 x N\n",
        "        c_avg = np.mean(noise, axis=1)  # M x 1\n",
        "\n",
        "        # Normalized correlation\n",
        "        def normalized_corr(a, b):\n",
        "            if np.std(a) == 0 or np.std(b) == 0:\n",
        "                return 0\n",
        "            return np.corrcoef(a, b)[0, 1]\n",
        "\n",
        "        rho_row = [normalized_corr(r_avg, noise[i, :]) for i in range(M)]\n",
        "        rho_col = [normalized_corr(c_avg, noise[:, j]) for j in range(N)]\n",
        "\n",
        "        # 15 features per channel\n",
        "        features = [\n",
        "            np.mean(rho_row), np.std(rho_row), scipy.stats.skew(rho_row), scipy.stats.kurtosis(rho_row),\n",
        "            np.mean(rho_col), np.std(rho_col), scipy.stats.skew(rho_col), scipy.stats.kurtosis(rho_col),\n",
        "            np.std(r_avg), scipy.stats.skew(r_avg), scipy.stats.kurtosis(r_avg),\n",
        "            np.std(c_avg), scipy.stats.skew(c_avg), scipy.stats.kurtosis(c_avg),\n",
        "            (1 - np.mean(rho_col) / np.mean(rho_row)) * 100 if np.mean(rho_row) != 0 else 0\n",
        "        ]\n",
        "        all_features.extend(features)\n",
        "\n",
        "    return np.array(all_features)"
      ],
      "metadata": {
        "id": "qCoXoJwe8rjB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Dataset"
      ],
      "metadata": {
        "id": "ck9aAcl_EFTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(cg_folder, camera_folder):\n",
        "    X, y, filenames = [], [], []\n",
        "    for idx, file in enumerate(os.listdir(cg_folder)):\n",
        "        try:\n",
        "            img_path = os.path.join(cg_folder, file)\n",
        "            output_path = os.path.join(cropped_dir, f\"cg_image_{idx}_{file}\")\n",
        "            img = center_crop_image(img_path, output_path=output_path)\n",
        "            X.append(extract_features(img))\n",
        "            y.append(0)  # CG\n",
        "            filenames.append(file)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing CG image {file}: {e}\")\n",
        "            continue\n",
        "    for idx, file in enumerate(os.listdir(camera_folder)):\n",
        "        try:\n",
        "            img_path = os.path.join(camera_folder, file)\n",
        "            output_path = os.path.join(cropped_dir, f\"camera_image_{idx}_{file}\")\n",
        "            img = center_crop_image(img_path, output_path=output_path)\n",
        "            X.append(extract_features(img))\n",
        "            y.append(1)  # Camera\n",
        "            filenames.append(file)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing Camera image {file}: {e}\")\n",
        "            continue\n",
        "    return np.array(X), np.array(y), filenames"
      ],
      "metadata": {
        "id": "loYH2p7B8xEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to datasets\n",
        "cg_folder = \"/content/drive/MyDrive/DIP_CG\"\n",
        "camera_folder = \"/content/drive/MyDrive/DIP_DigitalCamera\"# Load dataset\n",
        "X, y, filenames = load_dataset(cg_folder, camera_folder)\n",
        "\n",
        "# Check class balance\n",
        "print(f\"CG images: {sum(y == 0)}, Camera images: {sum(y == 1)}\")\n",
        "\n",
        "# Save feature vectors\n",
        "feature_names = []\n",
        "channels = [\"red\", \"green\", \"blue\"]\n",
        "for channel in channels:\n",
        "    feature_names.extend([\n",
        "        f\"{channel}_rho_row_mean\", f\"{channel}_rho_row_std\", f\"{channel}_rho_row_skew\", f\"{channel}_rho_row_kurtosis\",\n",
        "        f\"{channel}_rho_col_mean\", f\"{channel}_rho_col_std\", f\"{channel}_rho_col_skew\", f\"{channel}_rho_col_kurtosis\",\n",
        "        f\"{channel}_r_avg_std\", f\"{channel}_r_avg_skew\", f\"{channel}_r_avg_kurtosis\",\n",
        "        f\"{channel}_c_avg_std\", f\"{channel}_c_avg_skew\", f\"{channel}_c_avg_kurtosis\",\n",
        "        f\"{channel}_ratio_feature\"\n",
        "    ])\n",
        "features_df = pd.DataFrame(X, columns=feature_names)\n",
        "features_df[\"label\"] = y\n",
        "features_df[\"filename\"] = filenames\n",
        "features_df.to_csv(os.path.join(results_dir, \"feature_vectors.csv\"), index=False)\n",
        "np.savez(os.path.join(results_dir, \"feature_vectors.npz\"), X=X, y=y, filenames=filenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyur-3q28_U3",
        "outputId": "24f9d8da-b1f6-4a1f-f1c4-f5f747f740ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:2922: RuntimeWarning: invalid value encountered in divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:2923: RuntimeWarning: invalid value encountered in divide\n",
            "  c /= stddev[None, :]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing CG image Copy of chevy1.jpg: Truncated File Read\n",
            "Error processing CG image Copy of PM_GAME.jpg: cannot identify image file '/content/drive/MyDrive/DIP_CG/Copy of PM_GAME.jpg'\n",
            "Error processing CG image Copy of jmlydf1.jpg: image file is truncated (22 bytes not processed)\n",
            "Error processing CG image Copy of noc1900.jpg: image file is truncated (2 bytes not processed)\n",
            "Error processing CG image Copy of chevy.jpg: Truncated File Read\n",
            "CG images: 246, Camera images: 251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing and SVM trainig"
      ],
      "metadata": {
        "id": "pT_Mgh7aENEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "# Handle NaNs with mean imputation\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = imputer.fit_transform(X)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# SVM with grid search for RBF kernel\n",
        "param_grid = {\n",
        "    'C': [1, 10, 100],\n",
        "    'gamma': [0.01, 0.001, 0.0001],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "grid = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "clf = grid.best_estimator_\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Save the trained SVM model\n",
        "model_path = os.path.join(results_dir, \"svm_model.joblib\")\n",
        "joblib.dump(clf, model_path)\n",
        "print(f\"SVM model saved to {model_path}\")\n",
        "\n",
        "print(\"Best SVM parameters:\", grid.best_params_)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"CG\", \"Camera\"], yticklabels=[\"CG\", \"Camera\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"CG vs Camera SVM Classification\")\n",
        "plt.savefig(os.path.join(results_dir, \"confusion_matrix.png\"), dpi=300, bbox_inches=\"tight\")\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnuuRqsgwY1j",
        "outputId": "2440ed54-f636-4e20-a334-b516edf4c459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM model saved to /content/drive/MyDrive/DIP_Output/results/svm_model.joblib\n",
            "Best SVM parameters: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81        49\n",
            "           1       0.82      0.80      0.81        51\n",
            "\n",
            "    accuracy                           0.81       100\n",
            "   macro avg       0.81      0.81      0.81       100\n",
            "weighted avg       0.81      0.81      0.81       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_pdf_for_features(pdf_path):\n",
        "\n",
        "    images = convert_from_path(pdf_path, first_page=1, last_page=1)\n",
        "\n",
        "    if not images:\n",
        "        raise ValueError(\"No images extracted from the PDF.\")\n",
        "\n",
        "    # Convert PIL image to numpy array (RGB format)\n",
        "    img_pil = images[0]\n",
        "    img = np.array(img_pil.convert('RGB'))\n",
        "\n",
        "    # Ensure image is in correct format (RGB)\n",
        "    if len(img.shape) != 3 or img.shape[2] != 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB if len(img.shape) == 2 else cv2.COLOR_RGBA2RGB)\n",
        "\n",
        "    # Call the original extract_features function\n",
        "    return extract_features(img)\n",
        "\n",
        "features = process_pdf_for_features(\"/content/Xerox_Versalink.PDF\")\n",
        "print(f\"Extracted features: {features}\")"
      ],
      "metadata": {
        "id": "tLszSgtKzVzR",
        "outputId": "3db35a58-4b03-46c8-bc11-452dcc480a8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted features: [-4.63989347e-02  2.65201083e-01  9.10990467e-02 -1.23476955e+00\n",
            "  3.72590373e-01  2.79367381e-01 -1.40845123e+00  5.93305253e-01\n",
            "  6.07044554e+00 -1.25209272e-01 -2.37691879e-01  1.98169575e+01\n",
            " -3.52196598e+00  1.64734478e+01  9.03014931e+02 -4.63989347e-02\n",
            "  2.65201083e-01  9.10990467e-02 -1.23476955e+00  3.72590373e-01\n",
            "  2.79367381e-01 -1.40845123e+00  5.93305253e-01  6.07044554e+00\n",
            " -1.25209272e-01 -2.37691879e-01  1.98169575e+01 -3.52196598e+00\n",
            "  1.64734478e+01  9.03014931e+02 -4.63989347e-02  2.65201083e-01\n",
            "  9.10990467e-02 -1.23476955e+00  3.72590373e-01  2.79367381e-01\n",
            " -1.40845123e+00  5.93305253e-01  6.07044554e+00 -1.25209272e-01\n",
            " -2.37691879e-01  1.98169575e+01 -3.52196598e+00  1.64734478e+01\n",
            "  9.03014931e+02]\n"
          ]
        }
      ]
    }
  ]
}